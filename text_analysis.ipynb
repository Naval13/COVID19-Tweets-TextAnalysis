{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "This assignment comprises the execution of analysing textual data i.e., converting the extracted data into a proper forma. The task is to preprocess a set of tweets and convert them into numerical representations (which are suitable for input into recommender-systems/ information-retrieval algorithms). The dataset contains 80+ days of COVID-19 related tweets (from late March to mid July 2020) with each sheet contains 2000 tweets. The required tasks are the following:\n",
    "\n",
    "1. Loading data from the all spreadsheets\n",
    "2. Tokenizing the extracted text\n",
    "3. Removing of context independent (stopword list from the provided file) and context dependent words with the threshold set to more than 60 days and rare tokens with a threshold of less than 5 days.\n",
    "4. Tokens with the length less than 3 should be removed from the vocab\n",
    "5. Generate the corpus vocabulary that must be sorted alphabetically.\n",
    "6. For each day (i.e., sheet in your excel file), calculate the top 100 frequent unigram and top-200 frequent bigrams \n",
    "7. Generate the sparse representation (i.e., doc-term matrix) of the excel file.\n",
    "\n",
    "\n",
    "More details for each task will be given in the following sections.\n",
    "\n",
    "Environment: Python 3.7 and Anaconda 4.3.0 (64-bit)\n",
    "\n",
    "Libraries used:\n",
    "* pandas 0.19.2 (for data frame, included in Anaconda Python 3.7) \n",
    "* re 2.2.1 (for regular expression, included in Anaconda Python 3.7) \n",
    "* langid (for identifying the language of the string, included in Anaconda Python 3.7)\n",
    "* nltk 3.2.2 (Natural Language Toolkit, included in Anaconda Python 3.7)\n",
    "* nltk.collocations (for finding bigrams, included in Anaconda Python 3.7)\n",
    "* nltk.tokenize (for tokenization, included in Anaconda Python 3.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import langid\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "import nltk.data\n",
    "from nltk.stem import PorterStemmer # Stemming \n",
    "from nltk.probability import * # for unigrams and FreqDistribution\n",
    "from nltk.util import ngrams #Bigrams\n",
    "\n",
    "from __future__ import division\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading data\n",
    "\n",
    "The dataset can be loaded from the GITHUB repository: https://github.com/Naval13/COVID19-Tweets-TextAnalysis/blob/main/tweet_dataset.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of excel_list  26\n"
     ]
    }
   ],
   "source": [
    "#list all the the files of the folder os.listdir() method \n",
    "# file_path = \"Sample Output/part2/sample.xlsx\"\n",
    "file_path = \"tweet_dataset.xlsx\"\n",
    "\n",
    "# Read the excel document using pandas\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "# Fetching the number of sheets existing in the document\n",
    "excel_list = excel_data.sheet_names\n",
    "\n",
    "print('Size of excel_list ', len(excel_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data_dict  26\n"
     ]
    }
   ],
   "source": [
    "# This method is used to parse each excel sheet\n",
    "# file_no: spreadsheet no of the excel document\n",
    "# return dataframe: dataframe containing columns as id, text and created_at \n",
    "def parse_excel(file_no):\n",
    "    # Parsing each spreadsheet \n",
    "    dataframe = excel_data.parse(file_no, header=None)\n",
    "    # Dropping all null(NA) rows and columns of each spread sheet \n",
    "    dataframe = dataframe.dropna(axis='rows', how='all')\n",
    "    dataframe = dataframe.dropna(axis='columns', how='all')\n",
    "    # Resetting the index makes index into the dataframe as a column\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "    # setting the header position to the first location\n",
    "    header = dataframe.iloc[0]\n",
    "    # Extracting the resst of the dataframe and removing the first row: text, id and created_at\n",
    "    dataframe = dataframe[1:]\n",
    "    # Renamingthe columns and resetting the index of the dataframe\n",
    "    dataframe = dataframe.rename(columns=header)\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "# Creating a data_dict and parsing each excel sheet \n",
    "data_dict = dict()\n",
    "for i in range(len(excel_list)):\n",
    "    # Storing the dataframe as a value for the corresponding sheet names in the data_dict dictionary \n",
    "    data_dict[excel_list[i]] = parse_excel(i)\n",
    "\n",
    "print(\"Size of data_dict \", len(data_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of text_dict  26\n"
     ]
    }
   ],
   "source": [
    "# This method is used parse the textual tweets of each file\n",
    "# file_name : file_name correspond to the name of the spread sheet into consideration\n",
    "# return raw_text: raw_text contains all data from the text column in lower cases into one string \n",
    "def parse_text(file_name):\n",
    "    # fetching the text from the entire column as a list \n",
    "    dataframe_text = data_dict.get(file_name).text.values\n",
    "    # Creating an empty english_list which will only contains english textual tweets\n",
    "    english_list = []\n",
    "    \n",
    "    # iterating from the list dataframe_text column and filtering out the engilsh tweets\n",
    "    for each_tweet in dataframe_text:\n",
    "        # identifying the language of each tweet\n",
    "        check_text = langid.classify(str(each_tweet))[0]\n",
    "        # Filtering out only the english tweets\n",
    "        if check_text == 'en':\n",
    "            # adding each english tweet\n",
    "            english_list.append(each_tweet)\n",
    "            \n",
    "    # Joining each enlish tweet \n",
    "    raw_text = '\\n'.join(str(v) for v in english_list)\n",
    "    # Converting all the raw_text into lower case \n",
    "    raw_text = raw_text.lower()\n",
    "\n",
    "    return raw_text\n",
    "\n",
    "# Creating a text_dict and parsing text for each excel sheet \n",
    "text_dict = dict()\n",
    "for i in range(len(excel_list)):\n",
    "    # Storing the english text as a string corresponding to sheet names in the text_dict dictionary \n",
    "    text_dict[excel_list[i]] = parse_text(excel_list[i])\n",
    "\n",
    "print(\"Size of text_dict \", len(text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2020-07-25', '2020-07-24', '2020-07-26', '2020-07-27', '2020-07-28', '2020-07-29', '2020-07-30', '2020-07-31', '2020-08-01', '2020-08-02', '2020-08-04', '2020-08-06', '2020-08-07', '2020-08-08', '2020-08-09', '2020-08-10', '2020-08-11', '2020-08-12', '2020-08-13', '2020-08-14', '2020-08-16', '2020-08-17', '2020-08-18', '2020-08-22', '2020-08-30', '2020-08-29'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations :- \n",
    "\n",
    "1. Parsing each text column of the spreadsheet and converting all the list in the form of a string.\n",
    "2. Language of each text is identified using langid module and filtering is done. \n",
    "3. The extracted string is converted to lower case so that there is no mismatch of words.\n",
    "4. Dictionary text_dict of size 81, is created key as each file name and its value as a string of just english tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Pre - Processing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Word Tokenization\n",
    "\n",
    "#### The aim is to break long sequences of characters into word tokens. The task of breaking a character sequence into pieces is known as tokenization. These tokens are referred as unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating main_dict for tokenized text\n",
    "# tokenized text: a token is an instance of a sequence of characters in some particular document that are grouped \n",
    "# together as a useful semantic unit for processing  \n",
    "main_dict = dict()\n",
    "# Finding tokenizer with an help of provided regular expression\n",
    "tokenizer = RegexpTokenizer(r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\")\n",
    "\n",
    "# Iterating the values of all english tweets and creating the unigrams \n",
    "for j in text_dict.keys():\n",
    "    unigram_tokens = tokenizer.tokenize(text_dict[j])\n",
    "    main_dict[j] = unigram_tokens\n",
    "    \n",
    "# print(unigram_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations: \n",
    "\n",
    "1. Using tokenizer, the text is to tokenised using given regular expression \n",
    "2. All the unigram tokens are stored in the main_dict dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Removing Stopwords: \n",
    "\n",
    "#### Stopwords are the words which do not contribute any meaning to a sentence. They can safely be removed without sacrificing the meaning of the sentence.  For this task, all the provided stopwords are listed in a file and these can be used to safely remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of stopwords list  571\n"
     ]
    }
   ],
   "source": [
    "# This method is used to parse english stopwords from a file\n",
    "# return the list of stop words \n",
    "def get_stopwords_from_file():\n",
    "    stopwords = []\n",
    "    \n",
    "    with open('./stopwords_en.txt') as f:\n",
    "        stopwords = f.read().splitlines()\n",
    "        \n",
    "    return stopwords\n",
    "\n",
    "\n",
    "# fetching a list of given stopwords\n",
    "stopwords = get_stopwords_from_file()\n",
    "print('Size of stopwords list ', len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method is used to remove wordslist from the dict\n",
    "# stopwords_list : list of stopwords\n",
    "# remove_dict : dictionary from where list of stopwords are needed to be removed\n",
    "# return new_dict: updated new dictionary with the removed words\n",
    "def remove_words_from_list(stopwords_list, remove_dict):\n",
    "    # after removing stop words \n",
    "    new_dict ={}\n",
    "    # Converted to set for faster searching in set\n",
    "    stopwords_set = set(stopwords_list)\n",
    "    for y in remove_dict.keys():\n",
    "        new_dict[y] = [w for w in remove_dict[y] if w not in stopwords_set]\n",
    "    \n",
    "    # returning the updated dictionary \n",
    "    return new_dict    \n",
    "\n",
    "# initial_unigram_dict contain the dictionary with the unigrams with the removed stopwords\n",
    "initial_unigram_dict = remove_words_from_list(stopwords, main_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "\n",
    "1. Creating a new dictionary initial_unigram_dict which stores all the tokens without stopwords. \n",
    "2. This type of stopwords removal is context independent removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Stemming\n",
    "\n",
    "#### The task of stemming is to reduce the same word in different lexical forms to its base form without significantly loosing the meaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method is used to stem and compress the dictionary\n",
    "# required_dict: dictionary which is required and the stemming and compressing of words done \n",
    "# return stem_dict with all compression of words in the dictionary\n",
    "def stem_compressing(required_dict):\n",
    "    stem_dict = {}\n",
    "    stem = PorterStemmer()\n",
    "\n",
    "    for z in required_dict.keys():\n",
    "        stem_dict[z] = [stem.stem(w) for w in required_dict[z]]\n",
    "    \n",
    "    return stem_dict\n",
    "\n",
    "\n",
    "stem_compress_dict = stem_compressing(initial_unigram_dict)\n",
    "# print(stem_compress_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:   Stemming the words is done with tokens in different form are converted into its base form without significantly loosing its meaning. These are then added to the new dictionary stem_compress_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Unigrams and Bigrams \n",
    "\n",
    "#### Creating unigram and bigram files by 100 most common tokens and their frequency count using FreqDist function stem_compress_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2020-07-25', '2020-07-24', '2020-07-26', '2020-07-27', '2020-07-28', '2020-07-29', '2020-07-30', '2020-07-31', '2020-08-01', '2020-08-02', '2020-08-04', '2020-08-06', '2020-08-07', '2020-08-08', '2020-08-09', '2020-08-10', '2020-08-11', '2020-08-12', '2020-08-13', '2020-08-14', '2020-08-16', '2020-08-17', '2020-08-18', '2020-08-22', '2020-08-30', '2020-08-29'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_compress_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing 100 most common unigrams\n",
    "with open('31153054_100uni_test.txt', 'w', encoding='utf-8') as f:\n",
    "    for sheet in stem_compress_dict.keys():\n",
    "        f.write(sheet+':'+ str(FreqDist(stem_compress_dict[sheet]).most_common(100))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing 100 most common bigrams\n",
    "with open('3153054_100bi_test.txt', 'w', encoding='utf-8') as f:\n",
    "    for sheet in main_dict.keys():\n",
    "        bigrams = ngrams(main_dict[sheet],n=2)\n",
    "        fdbigram = FreqDist(bigrams)\n",
    "        f.write(sheet+':'+ str(fdbigram.most_common(100))+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Vocab List: It contains the list of unique words contained in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  32023 \n",
      "Total number of tokens:  216257 \n",
      "Lexical diversity:  6.753177403741061\n"
     ]
    }
   ],
   "source": [
    "# containing all the tokens from all the sheets\n",
    "words_list = list(chain.from_iterable(main_dict.values()))\n",
    "vocab = set(words_list)\n",
    "lexical_diversity = len(words_list)/len(vocab)\n",
    "print (\"Vocabulary size: \",len(vocab),\"\\nTotal number of tokens: \", len(words_list), \\\n",
    "\"\\nLexical diversity: \", lexical_diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "1. It is observed that the vocabulary size is 200237, which is quite large according to our knowledge. \n",
    "2. This tells us that words occur on average about 11.567 times each. \n",
    "3. There are words that occur very frequently, such as stopwords, and those that only occur once or twice, it might not help you at all and would only contribute noise. Similarly if a word appears only once in a corpus or only in one document of the corpus, it could carry little useful information for downstream analysis. \n",
    "4. Therefore, these are also removed from the vocabulary, for better the text analysis algorithms in terms of reducing running time and memory requirement, and improving their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa75b887790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_distribution = FreqDist(words_list)\n",
    "# Checking the frequency of words coming\n",
    "frequency_distribution.plot(25, cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: Shows 25 words to occur 760000 which can be removed easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22889"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# happen only once\n",
    "len(frequency_distribution.hapaxes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: Shows 153535 words occur only once which can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting bigrams from the bag of words\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = nltk.collocations.BigramCollocationFinder.from_words(words_list)\n",
    "bigram_list=finder.nbest(bigram_measures.pmi, 200)\n",
    "# print(bigram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending bigrams to unigrams dictionary \n",
    "merged_dict = dict()\n",
    "for i in initial_unigram_dict.keys():\n",
    "    # Adding bigram_list to the list of unigram listing\n",
    "    merged_dict[i] = list(bigram_list + initial_unigram_dict[i])\n",
    "\n",
    "# print(merged_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. MWE Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new empty dictionay \n",
    "mwe_tokenizer_dict = dict()\n",
    "\n",
    "for i in merged_dict.keys():\n",
    "    mwe_tokenizer = MWETokenizer(merged_dict[i])\n",
    "    mwe_tokenizer_dict[i] = mwe_tokenizer.tokenize(initial_unigram_dict[i])\n",
    "\n",
    "# print(len(mwe_tokenizer_dict[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation:\n",
    "\n",
    "1. The raw_text has been split into a list of tokens that contains both unigrams and multi-word expressions. However, the list contains a lot of functional words, such as \"to\", \"in\", \"the\", \"is\" and so on. \n",
    "2. These functional words usually do not contribute much to the semantics of the text, except for increase the dimensionality of the data in text analysis. \n",
    "3. Therefore, we can choose to remove those words, which is your next task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Tokens Removal\n",
    "\n",
    "#### Removing rare token and context dependent tokens if there occurences is with threshold less than 5 days or more than 60 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for x in mwe_tokenizer_dict.keys():\n",
    "    for y in mwe_tokenizer_dict[x]:\n",
    "        if len(y) < 3:\n",
    "            tokens.append(y)\n",
    "\n",
    "token_removal_dict = remove_words_from_list(tokens, mwe_tokenizer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating two dictionaries \n",
    "bigram_dict = {}\n",
    "unigram_dict = {}\n",
    "\n",
    "for i in token_removal_dict.keys():\n",
    "    unigram_dict[i] = [x for x in token_removal_dict[i] if \"_\" not in x]\n",
    "    bigram_dict[i] = [x for x in token_removal_dict[i] if \"_\" in x]\n",
    "    \n",
    "#print(unigram_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28300\n"
     ]
    }
   ],
   "source": [
    "threshold_list = []\n",
    "\n",
    "unique_words_list = list(chain.from_iterable([set(value) for value in  unigram_dict.values()]))\n",
    "fd = FreqDist(unique_words_list)\n",
    "tuple_threshold = fd.most_common()\n",
    "\n",
    "for j in range(len(tuple_threshold)):\n",
    "    if tuple_threshold[j][1] < 5 or tuple_threshold[j][1] > 60:\n",
    "        threshold_list.append(tuple_threshold[j][0])\n",
    "    \n",
    "    \n",
    "print(len(threshold_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing threshold words for the dictionary\n",
    "threshold_final = remove_words_from_list(threshold_list, unigram_dict)\n",
    "# print(threshold_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stem_dict = stem_compressing(threshold_final)\n",
    "#print(final_stem_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining bigram and unigram(after removing stop words)\n",
    "result = {}\n",
    "\n",
    "for i in final_stem_dict.keys():\n",
    "    result[i] = [x for x in final_stem_dict[i]]\n",
    "    result[i] = result[i] + bigram_dict[i]\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of sorted_vocab_set :  1836\n"
     ]
    }
   ],
   "source": [
    "# vocab list is created using chaining of each value in the result dict\n",
    "vocab_final_list = list(chain.from_iterable(result.values()))\n",
    "\n",
    "# Creating a set of unique vocab list \n",
    "vocab_set = set(vocab_final_list)\n",
    "# print(vocab_final_set)\n",
    "sorted_vocab_set = sorted(list(vocab_set))\n",
    "print('Size of sorted_vocab_set : ',len(sorted_vocab_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vocab list from the sorted set of vocabs i.e. these words exist \n",
    "with open('31153054_vocab.txt','w', encoding='utf-8') as f:\n",
    "    for index in range(len(c)):\n",
    "        f.write(c[index]+\":\"+str(index)+\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 11228)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\") \n",
    "\n",
    "data_features = vectorizer.fit_transform([' '.join(value) for value in result.values()])\n",
    "print (data_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('31153054_countVec.txt','w',encoding='utf-8') as f:\n",
    "    dict_index = 0\n",
    "    for x in result.keys():\n",
    "        start = x\n",
    "        for word, count in zip(sorted_vocab_set, data_features.toarray()[dict_index]):\n",
    "            if count > 0:\n",
    "                start = start + \",\" + str(sorted_vocab_set.index(word)) + \":\" + str(count)\n",
    "        dict_index = dict_index + 1\n",
    "        f.write(start + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "1. The raw_text has been split into a list of tokens that contains both unigrams and multi-word expressions. However, the list contains a lot of functional words, such as \"to\", \"in\", \"the\", \"is\" and so on. \n",
    "2. These functional words usually do not contribute much to the semantics of the text, except for increase the dimensionality of the data in text analysis. \n",
    "3. Also, note that our goal is to build a classification model of predicting fungal disease. Thus, we are more interested in the meaning of the diagnostic report than the syntax. Therefore, we can choose to remove those words, which is your next task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. References\n",
    "1. Blank B. (2011, January 19). *Regex non-consecutive chars* [Response to]. Retrieved from http://stackoverflow.com/a/4739636\n",
    "2. McKinney W. (2012, April 29). *Converting a Pandas GroupBy object to DataFrame* [Response to]. Retrieved from http://stackoverflow.com/a/10374456\n",
    "3. NLTK Project. (2017). *NLTK 3.0 documentation: `nltk.tokenize.regexp` module*. Retrieved from http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.regexp.RegexpTokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
